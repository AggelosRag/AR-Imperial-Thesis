{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from torchvision import datasets, transforms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T16:54:31.056765Z",
     "start_time": "2024-08-28T16:54:31.016858Z"
    }
   },
   "id": "4777cff0e00efc14"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "'/Users/gouse/PycharmProjects/AR-Imperial-Thesis'"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/Users/gouse/PycharmProjects/AR-Imperial-Thesis')\n",
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T16:54:31.086915Z",
     "start_time": "2024-08-28T16:54:31.021942Z"
    }
   },
   "id": "d12042f801e5db90"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23f23e1d3374fdcc"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "feature_names = [\"thickness_small\", \"thickness_medium\", \"thickness_large\", \"thickness_xlarge\",\n",
    "                 \"width_small\", \"width_medium\", \"width_large\", \"width_xlarge\",\n",
    "                 \"length_small\", \"length_medium\", \"length_large\", \"length_xlarge\"]\n",
    "\n",
    "class_names = [\"6\", \"8\", \"9\"]\n",
    "\n",
    "# mapping from feature index to feature name\n",
    "feature_index_to_name = {i: feature_name for i, feature_name in enumerate(feature_names)}\n",
    "# mapping from feature name to feature index\n",
    "feature_name_to_index = {feature_name: i for i, feature_name in enumerate(feature_names)}\n",
    "# mapping from class index to class name\n",
    "class_index_to_name = {i: class_name for i, class_name in enumerate(class_names)}\n",
    "# mapping from class name to class index\n",
    "class_name_to_index = {class_name: i for i, class_name in enumerate(class_names)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T16:54:31.087257Z",
     "start_time": "2024-08-28T16:54:31.027516Z"
    }
   },
   "id": "399b92d37f5172d7"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Download training and test sets\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize the images\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./datasets/MNIST/data', train=True,\n",
    "                               download=True,\n",
    "                               transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./datasets/MNIST/data', train=False,\n",
    "                              download=True,\n",
    "                              transform=transform)\n",
    "\n",
    "dict_of_lists = {6: [], 8: [], 9: []}\n",
    "for i, (_, label) in enumerate(train_dataset):\n",
    "    if label in dict_of_lists.keys():\n",
    "        dict_of_lists[label].append(\n",
    "            train_dataset.data[i].reshape(1, 28, 28))\n",
    "\n",
    "for key in dict_of_lists.keys():\n",
    "    dict_of_lists[key] = np.vstack(dict_of_lists[key]).reshape(-1, 1,\n",
    "                                                               28, 28)\n",
    "    if key == 8:\n",
    "        X = torch.cat((torch.tensor(dict_of_lists[6]),\n",
    "                       torch.tensor(dict_of_lists[8])))\n",
    "    elif key > 8:\n",
    "        X = torch.cat((X, torch.tensor(dict_of_lists[key])))\n",
    "\n",
    "# import pickle files\n",
    "with open('./datasets/MNIST/mine_preprocessed/area_dict.pkl', 'rb') as f:\n",
    "    area = pickle.load(f)\n",
    "with open('./datasets/MNIST/mine_preprocessed/length_dict.pkl', 'rb') as f:\n",
    "    length = pickle.load(f)\n",
    "with open('./datasets/MNIST/mine_preprocessed/thickness_dict.pkl', 'rb') as f:\n",
    "    thickness = pickle.load(f)\n",
    "with open('./datasets/MNIST/mine_preprocessed/slant_dict.pkl', 'rb') as f:\n",
    "    slant = pickle.load(f)\n",
    "with open('./datasets/MNIST/mine_preprocessed/width_dict.pkl', 'rb') as f:\n",
    "    width = pickle.load(f)\n",
    "with open('./datasets/MNIST/mine_preprocessed/height_dict.pkl', 'rb') as f:\n",
    "    height = pickle.load(f)\n",
    "\n",
    "# load the targets test\n",
    "with open('./datasets/MNIST/mine_preprocessed/area_dict_test.pkl', 'rb') as f:\n",
    "    area_test = pickle.load(f)\n",
    "with open('./datasets/MNIST/mine_preprocessed/length_dict_test.pkl', 'rb') as f:\n",
    "    length_test = pickle.load(f)\n",
    "with open('./datasets/MNIST/mine_preprocessed/thickness_dict_test.pkl', 'rb') as f:\n",
    "    thickness_test = pickle.load(f)\n",
    "with open('./datasets/MNIST/mine_preprocessed/slant_dict_test.pkl', 'rb') as f:\n",
    "    slant_test = pickle.load(f)\n",
    "with open('./datasets/MNIST/mine_preprocessed/width_dict_test.pkl', 'rb') as f:\n",
    "    width_test = pickle.load(f)\n",
    "with open('./datasets/MNIST/mine_preprocessed/height_dict_test.pkl', 'rb') as f:\n",
    "    height_test = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T16:54:33.726177Z",
     "start_time": "2024-08-28T16:54:31.037659Z"
    }
   },
   "id": "f3accd7b5d74fd5f"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0\n",
      "  Bin 1: Min = 1.0608199852609512, Max = 2.0955714117145585\n",
      "    Closest to Min: [ 5950  6513 16167  1617  8621]\n",
      "    Closest to Max: [ 5724 15599 12669 15554 15557]\n",
      "  Bin 2: Min = 2.095583355223437, Max = 2.455555185927587\n",
      "    Closest to Min: [  157 11735  2878 11170  5908]\n",
      "    Closest to Max: [10186    92 12276  7142 11892]\n",
      "  Bin 3: Min = 2.455627281914512, Max = 2.901642846528742\n",
      "    Closest to Min: [9156 6174 7889 4619 3771]\n",
      "    Closest to Max: [  244   426  4118  5549 12352]\n",
      "  Bin 4: Min = 2.9016807521673793, Max = 9.53389237525011\n",
      "    Closest to Min: [17317  8534  9637 12831 12134]\n",
      "    Closest to Max: [ 6880 11069  6466  8310 10537]\n",
      "Feature 1\n",
      "  Bin 1: Min = 5.381124287425585, Max = 10.939789083379203\n",
      "    Closest to Min: [12129 10069  1848  2104  1426]\n",
      "    Closest to Max: [  295 14518 15892 14841 10100]\n",
      "  Bin 2: Min = 10.940738953737265, Max = 12.576095107156878\n",
      "    Closest to Min: [11208  4297  6288  6421 12348]\n",
      "    Closest to Max: [11690 16675 17656 10882 16855]\n",
      "  Bin 3: Min = 12.57627552105846, Max = 14.53266088562656\n",
      "    Closest to Min: [10795  1230   974 17043 16225]\n",
      "    Closest to Max: [ 4033 16861 15528  2335  2363]\n",
      "  Bin 4: Min = 14.53321565083615, Max = 21.116715020198313\n",
      "    Closest to Min: [ 1265 14605 16776 17406  3546]\n",
      "    Closest to Max: [15279  4458  2270 13351 15146]\n",
      "Feature 2\n",
      "  Bin 1: Min = 15.010407640085656, Max = 42.074116139070405\n",
      "    Closest to Min: [14013 11069  1045  2741  1559]\n",
      "    Closest to Max: [17097  2415 12566  2643  1360]\n",
      "  Bin 2: Min = 42.07716446627535, Max = 47.85229073212243\n",
      "    Closest to Min: [ 4615  2160 16288  8562 15961]\n",
      "    Closest to Max: [2148 4471 3860 2912 3597]\n",
      "  Bin 3: Min = 47.85965004500313, Max = 54.46625176280135\n",
      "    Closest to Min: [ 3554 12021  7628 15006  3844]\n",
      "    Closest to Max: [10118  7882  1385  6383 10381]\n",
      "  Bin 4: Min = 54.47361107568206, Max = 93.52133829043453\n",
      "    Closest to Min: [ 3400  3818 10753  2259  5021]\n",
      "    Closest to Max: [ 2884 10182 10668  8408  6162]\n"
     ]
    }
   ],
   "source": [
    "targets = []\n",
    "digits_size = 0\n",
    "labels = []\n",
    "# for i in range(4,10):\n",
    "for i in [6, 8, 9]:\n",
    "    # targets += list(\n",
    "    #     zip(thickness[i], width[i], slant[i], height[i]))\n",
    "    targets += list(\n",
    "        zip(thickness[i], width[i], length[i]))\n",
    "    # targets += list(\n",
    "    # zip(thickness[i], area[i], length[i],\n",
    "    #                     width[i], height[i], slant[i]))\n",
    "    if i == 6:\n",
    "        k = 0\n",
    "    elif i == 8:\n",
    "        k = 1\n",
    "    else:\n",
    "        k = 2\n",
    "    # labels.append([(i-4) for j in range(len(targets) - digits_size)])\n",
    "    labels.append([k for j in range(len(targets) - digits_size)])\n",
    "    digits_size += len(width[i])\n",
    "\n",
    "targets = np.array(targets)\n",
    "\n",
    "def assign_bins(data, bin_edges):\n",
    "    return np.digitize(data, bins=bin_edges, right=True)\n",
    "\n",
    "# Convert bin numbers to one-hot encoded values\n",
    "def one_hot_encode(bin_numbers, num_bins):\n",
    "    return np.eye(num_bins)[bin_numbers - 1]\n",
    "\n",
    "def process_data(targets, num_bins=4):\n",
    "    bins_data_all_indices = {}\n",
    "    bins_data_all = []\n",
    "    min_max_values_all = []\n",
    "    closest_images_all = []\n",
    "    bin_counts = []\n",
    "\n",
    "    for i in range(targets.shape[1]):\n",
    "        # Combine the data\n",
    "        combined_data = list(targets[:, i])\n",
    "\n",
    "        # Sort the combined data\n",
    "        combined_sorted = np.sort(combined_data)\n",
    "\n",
    "        # Determine the number of data points per bin\n",
    "        bin_size = len(combined_sorted) // num_bins\n",
    "\n",
    "        # Calculate bin edges\n",
    "        bin_edges = [combined_sorted[i * bin_size] for i in range(1, num_bins)] + [combined_sorted[-1]]\n",
    "        bin_edges = [-np.inf] + bin_edges\n",
    "\n",
    "        # Assign bins to the original data lists\n",
    "        bins_data = assign_bins(targets[:, i], bin_edges)\n",
    "\n",
    "        # Do one-hot encoding in the bins\n",
    "        bins_data_encoded = one_hot_encode(bins_data, num_bins)\n",
    "\n",
    "        # Get min and max values per bin\n",
    "        min_max_values = []\n",
    "        closest_images = []\n",
    "        counts = []\n",
    "\n",
    "        feature_bins_data = {}\n",
    "\n",
    "        for bin_num in range(1, num_bins + 1):\n",
    "            bin_indices = np.where(bins_data == bin_num)[0]\n",
    "            bin_values = targets[bin_indices, i]\n",
    "            counts.append(len(bin_indices))\n",
    "\n",
    "            if len(bin_values) > 0:\n",
    "                min_val = np.min(bin_values)\n",
    "                max_val = np.max(bin_values)\n",
    "                min_max_values.append((min_val, max_val))\n",
    "\n",
    "                # Select 5 images closest to the minimum and 5 closest to the maximum\n",
    "                closest_min_indices = bin_indices[np.argsort(np.abs(bin_values - min_val))[:5]]\n",
    "                closest_max_indices = bin_indices[np.argsort(np.abs(bin_values - max_val))[:5]]\n",
    "                closest_images.append((closest_min_indices, closest_max_indices))\n",
    "            else:\n",
    "                min_max_values.append((None, None))\n",
    "                closest_images.append(([], []))\n",
    "                \n",
    "            feature_bins_data[bin_num] = list(bin_indices)\n",
    "\n",
    "        bins_data_all.append(bins_data_encoded)\n",
    "        bins_data_all_indices[i] = feature_bins_data\n",
    "        min_max_values_all.append(min_max_values)\n",
    "        closest_images_all.append(closest_images)\n",
    "        bin_counts.append(counts)\n",
    "\n",
    "    return bins_data_all, bins_data_all_indices, min_max_values_all, closest_images_all, bin_counts\n",
    "\n",
    "# Example usage:\n",
    "#targets = np.random.randn(100, 2)  # Example targets with 2 features and 100 samples\n",
    "num_bins = 4\n",
    "bins_data_all, bins_data_all_indices, min_max_values_all, closest_images_all, bin_counts = process_data(targets, num_bins=num_bins)\n",
    "\n",
    "# Output the results\n",
    "for feature_idx in range(targets.shape[1]):\n",
    "    print(f\"Feature {feature_idx}\")\n",
    "    for bin_idx, (min_val, max_val) in enumerate(min_max_values_all[feature_idx]):\n",
    "        print(f\"  Bin {bin_idx + 1}: Min = {min_val}, Max = {max_val}\")\n",
    "        print(f\"    Closest to Min: {closest_images_all[feature_idx][bin_idx][0]}\")\n",
    "        print(f\"    Closest to Max: {closest_images_all[feature_idx][bin_idx][1]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T16:54:33.757214Z",
     "start_time": "2024-08-28T16:54:33.738863Z"
    }
   },
   "id": "57408da9e0c603b"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/pzn2mzln089b14702jlw7cqm0000gn/T/ipykernel_5405/2629746947.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train, dtype=torch.float32)\n",
      "/var/folders/s6/pzn2mzln089b14702jlw7cqm0000gn/T/ipykernel_5405/2629746947.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val = torch.tensor(X_val, dtype=torch.float32)\n",
      "/var/folders/s6/pzn2mzln089b14702jlw7cqm0000gn/T/ipykernel_5405/2629746947.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "C = np.stack(bins_data_all, axis=1).reshape(-1, num_bins* targets.shape[1])\n",
    "y = np.array([item for sublist in labels for item in sublist])\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data\n",
    "def train_test_split_with_indices(*arrays, **options):\n",
    "    # Extract the test_size and train_size parameters if they exist\n",
    "    test_size = options.pop('test_size', None)\n",
    "    train_size = options.pop('train_size', None)\n",
    "    random_state = options.pop('random_state', None)\n",
    "    shuffle = options.pop('shuffle', True)\n",
    "    stratify = options.pop('stratify', None)\n",
    "    indices = options.pop('indices', None)\n",
    "\n",
    "    # Get the number of samples in the input arrays\n",
    "    n_samples = arrays[0].shape[0]\n",
    "\n",
    "    # Use provided indices or generate default indices\n",
    "    if indices is None:\n",
    "        indices = np.arange(n_samples)\n",
    "    \n",
    "    # Generate indices for the split\n",
    "    train_indices, test_indices = train_test_split(\n",
    "        indices, test_size=test_size, train_size=train_size, \n",
    "        random_state=random_state, shuffle=shuffle, stratify=stratify\n",
    "    )\n",
    "\n",
    "    # Split the arrays using the generated indices\n",
    "    result = []\n",
    "    for array in arrays:\n",
    "        result.append(array[train_indices])\n",
    "        result.append(array[test_indices])\n",
    "\n",
    "    # Append the indices to the result\n",
    "    result.append(train_indices)\n",
    "    result.append(test_indices)\n",
    "\n",
    "    return result\n",
    "\n",
    "X_train, X_val, C_train, C_val, y_train, y_val, train_indices, val_indices = train_test_split_with_indices(X, C, y,\n",
    "                                                                  test_size=0.5,\n",
    "                                                                  random_state=42)\n",
    "\n",
    "train_index_to_or_index = {i: original_idx for i, original_idx in enumerate(train_indices)}\n",
    "train_or_index_to_index = {original_idx: i for i, original_idx in enumerate(train_indices)}\n",
    "\n",
    "X_val, X_test, C_val, C_test, y_val, y_test, val_indices, test_indices = train_test_split_with_indices(X_val, C_val, y_val,\n",
    "                                                                  test_size=0.5,\n",
    "                                                                  random_state=42)\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "C_train = torch.tensor(C_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "C_val = torch.tensor(C_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "C_test = torch.tensor(C_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T16:54:33.791185Z",
     "start_time": "2024-08-28T16:54:33.755416Z"
    }
   },
   "id": "938ff1cf5610d467"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load test accuracies per leaf"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0545ad565990499"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "output_path = \"/Users/gouse/PycharmProjects/AR-Imperial-Thesis/logs_and_models_to_show/analysis_notebooks/completeness_scores/CBM_model_new\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T16:54:33.791496Z",
     "start_time": "2024-08-28T16:54:33.779085Z"
    }
   },
   "id": "20d71ccf6e077759"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "with open(os.path.join(output_path, 'accuracy_per_original_path_dict.pkl'), 'rb') as f:\n",
    "    accuracy_per_original_path_dict = pkl.load(f)\n",
    "with open(os.path.join(output_path, 'accuracy_per_new_path_dict.pkl'), 'rb') as f:\n",
    "    accuracy_per_new_path_dict = pkl.load(f)\n",
    "with open(os.path.join(output_path, 'leaf_samples_indices.pkl'), 'rb') as f:\n",
    "    leaf_samples_indices = pkl.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T16:54:33.791558Z",
     "start_time": "2024-08-28T16:54:33.782444Z"
    }
   },
   "id": "3a826de8ec3dacd7"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "{4: 0.6076923076923076,\n 6: 0.3469387755102041,\n 7: 0.573170731707317,\n 10: 0.4878048780487805,\n 11: 0.46,\n 12: 0.64,\n 15: 0.496996996996997,\n 16: 0.4946236559139785,\n 17: 0.9591836734693877,\n 18: 0.7394757744241461}"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_per_original_path_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T16:54:33.791694Z",
     "start_time": "2024-08-28T16:54:33.786213Z"
    }
   },
   "id": "9f1fc8937de3f943"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "{4: 0.6076923076923076,\n 6: 0.47619047619047616,\n 7: 0.573170731707317,\n 10: 0.4878048780487805,\n 11: 0.46,\n 12: 0.64,\n 15: 0.496996996996997,\n 16: 0.4946236559139785,\n 17: 0.9591836734693877,\n 18: 0.7942811755361397}"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_per_new_path_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T16:54:33.797552Z",
     "start_time": "2024-08-28T16:54:33.789692Z"
    }
   },
   "id": "928c73a46e8ffd27"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "{4: array([   5,    7,    9,   13,   19,   24,   32,   33,   36,   39,   41,\n          44,   47,   58,   62,   64,   68,   74,   76,   83,   84,   86,\n          92,   98,   99,  106,  115,  119,  120,  125,  128,  131,  134,\n         135,  142,  143,  151,  153,  156,  158,  162,  178,  181,  182,\n         196,  214,  216,  228,  229,  234,  235,  237,  239,  241,  245,\n         248,  249,  251,  255,  256,  268,  272,  276,  278,  281,  284,\n         286,  288,  290,  307,  311,  317,  318,  319,  321,  322,  327,\n         330,  339,  341,  361,  363,  364,  366,  371,  377,  388,  389,\n         391,  393,  394,  403,  404,  409,  410,  421,  424,  428,  436,\n         453,  455,  456,  476,  479,  481,  483,  491,  493,  503,  504,\n         512,  517,  518,  536,  538,  541,  543,  547,  553,  554,  560,\n         565,  570,  574,  581,  587,  593,  594,  598,  606,  609,  610,\n         614,  616,  620,  639,  642,  644,  646,  656,  663,  665,  684,\n         686,  688,  699,  730,  745,  755,  762,  770,  772,  779,  785,\n         796,  798,  801,  805,  809,  817,  821,  823,  824,  828,  830,\n         833,  843,  844,  846,  853,  854,  857,  858,  871,  879,  896,\n         901,  909,  910,  912,  918,  928,  931,  934,  938,  949,  950,\n         961,  965,  971,  974,  978,  987,  988,  993,  997, 1032, 1034,\n        1042, 1044, 1050, 1056, 1062, 1068, 1075, 1097, 1108, 1111, 1120,\n        1122, 1126, 1140, 1146, 1149, 1150, 1156, 1159, 1163, 1168, 1189,\n        1190, 1191, 1200, 1215, 1221, 1231, 1232, 1241, 1247, 1249, 1250,\n        1257, 1262, 1273, 1280, 1288, 1293, 1299, 1300, 1302, 1309, 1323,\n        1334, 1338, 1343, 1349, 1357, 1363, 1367, 1370, 1372, 1385, 1391,\n        1398, 1407, 1410, 1411, 1418, 1424, 1429, 1431, 1434, 1444, 1446,\n        1467, 1477, 1480, 1483, 1486, 1494, 1504, 1512, 1524, 1527, 1530,\n        1534, 1537, 1539, 1548, 1557, 1558, 1561, 1563, 1564, 1573, 1578,\n        1585, 1586, 1599, 1600, 1618, 1620, 1621, 1628, 1636, 1641, 1644,\n        1647, 1676, 1679, 1688, 1689, 1693, 1694, 1696, 1699, 1715, 1720,\n        1734, 1737, 1742, 1744, 1747, 1758, 1759, 1766, 1767, 1768, 1772,\n        1781, 1789, 1790, 1794, 1798, 1803, 1814, 1819, 1827, 1842, 1864,\n        1883, 1884, 1889, 1896, 1897, 1898, 1899, 1911, 1915, 1930, 1933,\n        1942, 1945, 1952, 1958, 1971, 1974, 1976, 1980, 1990, 1992, 1995,\n        2001, 2004, 2007, 2008, 2019, 2020, 2022, 2023, 2034, 2035, 2039,\n        2054, 2062, 2066, 2067, 2072, 2074, 2082, 2087, 2096, 2097, 2098,\n        2105, 2115, 2119, 2128, 2132, 2164, 2169, 2173, 2183, 2184, 2193,\n        2196, 2198, 2201, 2209, 2212, 2217, 2231, 2232, 2236, 2237, 2239,\n        2243, 2245, 2250, 2257, 2260, 2270, 2272, 2273, 2276, 2279, 2287,\n        2294, 2305, 2307, 2314, 2325, 2342, 2349, 2355, 2361, 2364, 2375,\n        2378, 2380, 2383, 2385, 2393, 2395, 2405, 2421, 2423, 2447, 2449,\n        2453, 2458, 2463, 2486, 2488, 2497, 2501, 2505, 2507, 2515, 2528,\n        2540, 2543, 2544, 2551, 2552, 2569, 2606, 2607, 2612, 2618, 2624,\n        2629, 2633, 2640, 2642, 2649, 2651, 2652, 2656, 2661, 2662, 2664,\n        2668, 2672, 2674, 2682, 2692, 2695, 2696, 2698, 2706, 2721, 2723,\n        2727, 2734, 2738, 2761, 2762, 2765, 2768, 2771, 2784, 2786, 2789,\n        2802, 2805, 2806, 2811, 2816, 2822, 2831, 2838, 2843, 2847, 2849,\n        2859, 2862, 2871, 2879, 2889, 2891, 2896, 2898, 2901, 2909, 2921,\n        2930, 2933, 2948, 2959, 2973, 2978, 2984, 2993, 3002, 3011, 3021,\n        3027, 3032, 3048, 3050, 3054, 3055, 3059, 3063, 3067, 3068, 3071,\n        3082, 3083, 3085, 3107, 3126, 3132, 3136, 3140, 3145, 3147, 3154,\n        3163, 3166, 3170, 3179, 3180, 3181, 3189, 3192, 3193, 3195, 3201,\n        3204, 3218, 3221, 3226, 3227, 3231, 3232, 3242, 3250, 3262, 3268,\n        3277, 3278, 3283, 3286, 3297, 3302, 3310, 3317, 3320, 3321, 3327,\n        3332, 3334, 3344, 3356, 3358, 3374, 3380, 3389, 3398, 3400, 3402,\n        3406, 3409, 3422, 3424, 3425, 3434, 3438, 3452, 3454, 3461, 3466,\n        3470, 3479, 3486, 3487, 3492, 3503, 3512, 3516, 3523, 3547, 3552,\n        3557, 3561, 3563, 3571, 3579, 3586, 3587, 3591, 3598, 3604, 3605,\n        3606, 3609, 3611, 3621, 3622, 3623, 3628, 3632, 3635, 3646, 3648,\n        3650, 3656, 3667, 3673, 3676, 3678, 3680, 3684, 3686, 3690, 3704,\n        3709, 3710, 3715, 3717, 3719, 3733, 3734, 3735, 3738, 3744, 3756,\n        3760, 3762, 3763, 3768, 3771, 3773, 3776, 3779, 3782, 3804, 3810,\n        3823, 3828, 3829, 3833, 3844, 3846, 3847, 3851, 3853, 3865, 3870,\n        3872, 3873, 3878, 3880, 3881, 3886, 3892, 3898, 3899, 3904, 3907,\n        3910, 3921, 3923, 3926, 3930, 3931, 3937, 3942, 3951, 3952, 3958,\n        3959, 3966, 3970, 3978, 3982, 3986, 3994, 3998, 4009, 4012, 4020,\n        4021, 4024, 4026, 4036, 4040, 4049, 4051, 4057, 4061, 4062, 4064,\n        4065, 4068, 4069, 4071, 4104, 4105, 4106, 4126, 4143, 4144, 4151,\n        4159, 4162, 4163, 4169, 4174, 4178, 4182, 4183, 4184, 4188, 4189,\n        4194, 4199, 4204, 4208, 4215, 4218, 4222, 4225, 4226, 4228, 4232,\n        4242, 4248, 4251, 4257, 4264, 4279, 4280, 4283, 4285, 4289, 4301,\n        4306, 4308, 4309, 4323, 4328, 4335, 4339, 4342, 4343, 4359, 4364,\n        4371, 4375, 4381, 4387, 4390, 4391, 4400, 4403, 4423, 4426]),\n 6: array([   0,  175,  222,  250,  296,  340,  348,  356,  382,  383,  386,\n         392,  420,  522,  590,  601,  607,  704,  841,  886,  894,  921,\n         962, 1014, 1022, 1055, 1082, 1096, 1117, 1124, 1151, 1153, 1183,\n        1228, 1230, 1233, 1234, 1285, 1286, 1290, 1301, 1352, 1373, 1381,\n        1384, 1393, 1401, 1420, 1438, 1443, 1460, 1526, 1584, 1611, 1617,\n        1624, 1680, 1681, 1706, 1718, 1776, 1793, 1878, 1882, 1901, 1909,\n        1913, 1943, 1957, 1959, 2029, 2070, 2091, 2161, 2185, 2223, 2274,\n        2295, 2309, 2327, 2328, 2340, 2389, 2399, 2428, 2470, 2496, 2517,\n        2558, 2568, 2623, 2626, 2798, 2820, 2853, 2892, 2899, 2980, 3039,\n        3069, 3092, 3094, 3213, 3230, 3240, 3249, 3251, 3326, 3349, 3369,\n        3404, 3415, 3419, 3439, 3447, 3460, 3473, 3509, 3533, 3544, 3549,\n        3566, 3590, 3626, 3724, 3793, 3809, 3832, 3837, 3843, 3983, 3989,\n        4003, 4023, 4043, 4063, 4203, 4227, 4239, 4252, 4253, 4269, 4275,\n        4281, 4284, 4345, 4374]),\n 7: array([  16,   21,   29,   31,   38,   45,   61,   67,   87,   89,   91,\n         118,  132,  137,  150,  160,  166,  170,  177,  183,  194,  195,\n         199,  201,  203,  209,  210,  215,  220,  223,  231,  233,  246,\n         259,  271,  275,  293,  297,  301,  303,  304,  313,  337,  350,\n         369,  390,  402,  407,  433,  437,  444,  445,  463,  467,  472,\n         511,  514,  550,  566,  572,  585,  592,  599,  602,  622,  628,\n         635,  643,  666,  687,  690,  693,  711,  714,  725,  728,  736,\n         737,  740,  751,  761,  773,  781,  799,  806,  816,  819,  822,\n         826,  835,  837,  842,  851,  870,  877,  890,  891,  893,  899,\n         923,  941,  942,  953,  979,  980,  996,  999, 1000, 1003, 1004,\n        1016, 1023, 1040, 1045, 1054, 1058, 1076, 1086, 1142, 1152, 1158,\n        1162, 1167, 1169, 1172, 1177, 1178, 1195, 1203, 1204, 1210, 1211,\n        1213, 1218, 1254, 1264, 1266, 1274, 1277, 1292, 1311, 1320, 1329,\n        1350, 1354, 1366, 1375, 1392, 1409, 1413, 1417, 1427, 1432, 1439,\n        1451, 1461, 1478, 1491, 1509, 1511, 1518, 1519, 1528, 1535, 1542,\n        1545, 1565, 1579, 1587, 1591, 1615, 1632, 1634, 1638, 1654, 1657,\n        1661, 1665, 1669, 1675, 1677, 1690, 1695, 1707, 1708, 1716, 1723,\n        1727, 1753, 1754, 1756, 1782, 1784, 1786, 1791, 1795, 1802, 1808,\n        1813, 1816, 1826, 1837, 1847, 1862, 1869, 1871, 1873, 1874, 1880,\n        1891, 1893, 1912, 1914, 1920, 1932, 1944, 1947, 1960, 1961, 1966,\n        1968, 1975, 1989, 1997, 2012, 2021, 2024, 2026, 2046, 2055, 2083,\n        2088, 2093, 2094, 2107, 2126, 2127, 2131, 2133, 2138, 2143, 2179,\n        2191, 2202, 2211, 2235, 2241, 2247, 2252, 2255, 2256, 2264, 2271,\n        2289, 2334, 2337, 2352, 2365, 2413, 2414, 2415, 2426, 2429, 2430,\n        2442, 2459, 2460, 2471, 2474, 2476, 2487, 2503, 2504, 2523, 2530,\n        2532, 2537, 2548, 2549, 2557, 2562, 2563, 2586, 2588, 2632, 2635,\n        2636, 2648, 2659, 2660, 2663, 2670, 2673, 2680, 2683, 2703, 2718,\n        2722, 2740, 2757, 2782, 2783, 2795, 2809, 2810, 2812, 2837, 2851,\n        2865, 2877, 2903, 2906, 2913, 2918, 2919, 2925, 2932, 2939, 2942,\n        2946, 2949, 2960, 2961, 2962, 2989, 3001, 3016, 3019, 3020, 3030,\n        3036, 3041, 3042, 3045, 3060, 3074, 3081, 3091, 3104, 3118, 3119,\n        3122, 3127, 3141, 3152, 3164, 3187, 3191, 3207, 3212, 3216, 3245,\n        3256, 3269, 3274, 3276, 3284, 3292, 3309, 3312, 3313, 3324, 3342,\n        3346, 3367, 3395, 3405, 3431, 3441, 3444, 3458, 3474, 3475, 3482,\n        3484, 3488, 3514, 3522, 3527, 3530, 3534, 3535, 3537, 3548, 3568,\n        3569, 3570, 3576, 3581, 3582, 3585, 3599, 3624, 3637, 3638, 3642,\n        3651, 3654, 3670, 3671, 3689, 3699, 3702, 3708, 3721, 3722, 3727,\n        3741, 3753, 3764, 3780, 3783, 3792, 3796, 3806, 3807, 3814, 3820,\n        3839, 3841, 3858, 3859, 3860, 3877, 3900, 3913, 3929, 3935, 3938,\n        3954, 3981, 3987, 3990, 4042, 4053, 4070, 4076, 4077, 4078, 4081,\n        4084, 4085, 4086, 4093, 4095, 4103, 4107, 4108, 4111, 4118, 4134,\n        4139, 4147, 4149, 4167, 4168, 4170, 4176, 4177, 4179, 4180, 4185,\n        4186, 4196, 4198, 4205, 4210, 4211, 4223, 4229, 4233, 4249, 4259,\n        4260, 4265, 4268, 4276, 4290, 4292, 4302, 4314, 4317, 4318, 4331,\n        4350, 4351, 4372, 4376, 4377, 4384, 4412, 4416]),\n 10: array([   1,    6,   40,   48,   56,   65,   79,  140,  146,  174,  176,\n         221,  225,  252,  257,  274,  335,  355,  359,  372,  373,  380,\n         400,  425,  427,  470,  485,  488,  506,  520,  539,  549,  557,\n         576,  626,  627,  634,  648,  657,  673,  695,  708,  726,  731,\n         734,  752,  771,  780,  848,  850,  852,  868,  872,  887,  957,\n         967,  975,  982,  989, 1001, 1030, 1038, 1065, 1080, 1088, 1127,\n        1170, 1175, 1188, 1207, 1252, 1256, 1261, 1268, 1269, 1278, 1360,\n        1364, 1396, 1428, 1500, 1513, 1520, 1546, 1560, 1566, 1597, 1664,\n        1691, 1714, 1719, 1764, 1820, 1844, 1859, 1867, 1870, 1902, 1926,\n        1935, 1965, 2013, 2028, 2042, 2050, 2076, 2111, 2167, 2192, 2205,\n        2214, 2215, 2229, 2246, 2262, 2306, 2323, 2326, 2329, 2332, 2403,\n        2407, 2411, 2481, 2506, 2522, 2555, 2605, 2697, 2720, 2780, 2785,\n        2788, 2792, 2804, 2823, 2852, 2867, 2868, 2874, 2893, 2902, 2952,\n        2955, 2965, 2975, 3034, 3051, 3062, 3095, 3120, 3185, 3236, 3246,\n        3280, 3295, 3298, 3338, 3363, 3394, 3397, 3410, 3436, 3440, 3451,\n        3513, 3519, 3550, 3578, 3580, 3595, 3634, 3660, 3662, 3666, 3672,\n        3681, 3718, 3742, 3746, 3772, 3795, 3799, 3815, 3840, 3862, 3885,\n        3915, 3979, 4079, 4090, 4102, 4121, 4175, 4206, 4250, 4258, 4288,\n        4307, 4346, 4395, 4398, 4409, 4417, 4418]),\n 11: array([  10,   18,   37,   53,   75,  114,  130,  133,  147,  148,  168,\n         172,  191,  202,  226,  253,  254,  265,  277,  299,  328,  329,\n         385,  434,  438,  460,  466,  475,  487,  489,  498,  510,  519,\n         521,  533,  552,  558,  564,  568,  571,  577,  578,  579,  584,\n         588,  596,  640,  647,  652,  660,  692,  716,  719,  732,  739,\n         747,  759,  764,  810,  832,  864,  874,  885,  888,  895,  905,\n         968, 1006, 1007, 1028, 1029, 1031, 1067, 1069, 1071, 1073, 1081,\n        1100, 1102, 1103, 1116, 1119, 1125, 1128, 1133, 1161, 1176, 1180,\n        1181, 1201, 1219, 1243, 1246, 1251, 1255, 1258, 1270, 1308, 1321,\n        1332, 1437, 1452, 1459, 1468, 1472, 1495, 1517, 1582, 1589, 1607,\n        1609, 1631, 1637, 1651, 1736, 1743, 1749, 1760, 1797, 1805, 1806,\n        1807, 1830, 1839, 1848, 1852, 1853, 1916, 1925, 1948, 1949, 1954,\n        1963, 1978, 1984, 1991, 1999, 2000, 2002, 2006, 2017, 2031, 2032,\n        2056, 2058, 2060, 2079, 2084, 2103, 2125, 2144, 2147, 2160, 2186,\n        2216, 2220, 2225, 2253, 2263, 2265, 2335, 2353, 2358, 2366, 2374,\n        2376, 2379, 2386, 2390, 2402, 2404, 2412, 2438, 2450, 2469, 2477,\n        2479, 2482, 2492, 2499, 2510, 2527, 2531, 2554, 2559, 2580, 2583,\n        2585, 2595, 2598, 2614, 2641, 2650, 2681, 2714, 2726, 2748, 2755,\n        2758, 2779, 2793, 2835, 2850, 2860, 2866, 2912, 2914, 2928, 2940,\n        2944, 2967, 2990, 2995, 2996, 3009, 3014, 3026, 3044, 3064, 3066,\n        3076, 3080, 3096, 3112, 3114, 3121, 3133, 3146, 3162, 3167, 3171,\n        3200, 3210, 3233, 3234, 3243, 3253, 3272, 3306, 3314, 3316, 3336,\n        3354, 3381, 3403, 3408, 3417, 3449, 3450, 3462, 3476, 3478, 3489,\n        3493, 3531, 3539, 3545, 3551, 3554, 3610, 3669, 3687, 3692, 3700,\n        3707, 3770, 3774, 3784, 3785, 3786, 3790, 3825, 3866, 3871, 3889,\n        3950, 3953, 3973, 3976, 3991, 3999, 4029, 4056, 4099, 4112, 4124,\n        4128, 4129, 4152, 4158, 4192, 4354, 4356, 4362, 4368, 4373, 4396,\n        4406, 4414, 4429]),\n 12: array([  30,   77,  112,  154,  159,  169,  187,  269,  315,  324,  332,\n         353,  358,  381,  429,  452,  497,  502,  528,  604,  623,  661,\n         712,  723,  750,  776,  825,  859,  867,  882,  883,  902,  929,\n         983,  984,  985, 1046, 1048, 1118, 1141, 1143, 1214, 1260, 1295,\n        1339, 1347, 1361, 1412, 1473, 1484, 1515, 1521, 1601, 1650, 1659,\n        1670, 1709, 1769, 1771, 1778, 1779, 1804, 1855, 1860, 1892, 1962,\n        1985, 2016, 2057, 2078, 2124, 2137, 2159, 2165, 2182, 2194, 2195,\n        2244, 2249, 2258, 2303, 2359, 2406, 2427, 2467, 2539, 2550, 2576,\n        2593, 2620, 2644, 2742, 2744, 2796, 2807, 2808, 2828, 2895, 2907,\n        2937, 2938, 3084, 3097, 3109, 3111, 3168, 3182, 3263, 3305, 3315,\n        3330, 3437, 3453, 3457, 3468, 3491, 3575, 3594, 3608, 3629, 3630,\n        3644, 3668, 3723, 3749, 3759, 3819, 3824, 3850, 3852, 3909, 3927,\n        3948, 3961, 3974, 3997, 4005, 4030, 4052, 4058, 4060, 4113, 4140,\n        4187, 4234, 4255, 4271, 4272, 4326, 4408]),\n 15: array([  12,   14,   23,   27,   46,   52,   54,   71,   73,   81,   93,\n          94,   95,  108,  111,  123,  124,  126,  127,  155,  157,  173,\n         185,  186,  205,  212,  218,  224,  258,  264,  270,  273,  283,\n         285,  287,  291,  292,  294,  295,  309,  314,  316,  326,  338,\n         344,  346,  351,  352,  357,  360,  370,  374,  378,  384,  387,\n         398,  401,  406,  408,  417,  457,  462,  465,  474,  478,  496,\n         499,  505,  515,  523,  529,  534,  546,  561,  563,  575,  605,\n         608,  612,  617,  631,  649,  653,  659,  662,  667,  674,  682,\n         689,  701,  702,  703,  705,  713,  720,  721,  724,  733,  735,\n         738,  746,  754,  757,  767,  769,  788,  791,  803,  807,  812,\n         814,  818,  827,  831,  840,  847,  849,  863,  866,  869,  873,\n         876,  884,  908,  915,  917,  925,  926,  933,  937,  940,  944,\n         948,  964,  966,  973,  976,  992,  998, 1015, 1020, 1024, 1059,\n        1066, 1072, 1095, 1107, 1109, 1114, 1121, 1131, 1132, 1135, 1138,\n        1139, 1147, 1154, 1164, 1165, 1166, 1186, 1192, 1194, 1196, 1199,\n        1202, 1208, 1209, 1217, 1220, 1227, 1236, 1242, 1244, 1248, 1253,\n        1259, 1271, 1279, 1287, 1291, 1296, 1312, 1327, 1331, 1333, 1340,\n        1341, 1344, 1346, 1358, 1362, 1365, 1369, 1371, 1374, 1376, 1382,\n        1383, 1388, 1389, 1394, 1399, 1402, 1405, 1416, 1426, 1430, 1435,\n        1436, 1448, 1454, 1458, 1464, 1469, 1485, 1488, 1489, 1493, 1501,\n        1522, 1523, 1532, 1536, 1543, 1544, 1550, 1555, 1581, 1588, 1602,\n        1608, 1622, 1623, 1629, 1630, 1633, 1655, 1662, 1683, 1684, 1686,\n        1697, 1698, 1701, 1704, 1711, 1717, 1721, 1722, 1724, 1725, 1726,\n        1728, 1731, 1751, 1757, 1774, 1799, 1801, 1811, 1812, 1815, 1823,\n        1849, 1856, 1861, 1865, 1868, 1881, 1895, 1904, 1905, 1906, 1922,\n        1923, 1924, 1927, 1931, 1936, 1941, 1964, 1972, 1973, 1986, 2009,\n        2014, 2033, 2037, 2043, 2048, 2053, 2065, 2071, 2073, 2080, 2089,\n        2095, 2108, 2110, 2114, 2118, 2139, 2142, 2145, 2148, 2149, 2155,\n        2157, 2158, 2162, 2168, 2170, 2177, 2208, 2210, 2218, 2222, 2224,\n        2234, 2242, 2251, 2259, 2267, 2268, 2278, 2281, 2282, 2284, 2286,\n        2290, 2291, 2302, 2308, 2312, 2322, 2333, 2341, 2350, 2354, 2369,\n        2370, 2371, 2377, 2381, 2387, 2388, 2400, 2408, 2410, 2419, 2422,\n        2424, 2441, 2454, 2457, 2461, 2462, 2473, 2485, 2490, 2493, 2498,\n        2500, 2511, 2513, 2514, 2516, 2521, 2535, 2564, 2567, 2574, 2577,\n        2579, 2590, 2599, 2601, 2602, 2604, 2608, 2609, 2611, 2622, 2627,\n        2628, 2643, 2657, 2671, 2675, 2679, 2684, 2686, 2693, 2701, 2708,\n        2709, 2710, 2711, 2716, 2728, 2729, 2730, 2731, 2737, 2741, 2750,\n        2756, 2760, 2770, 2781, 2790, 2797, 2801, 2813, 2818, 2824, 2827,\n        2829, 2832, 2834, 2836, 2840, 2842, 2845, 2857, 2875, 2876, 2878,\n        2880, 2884, 2885, 2887, 2904, 2908, 2910, 2931, 2945, 2947, 2953,\n        2974, 2979, 2986, 2988, 2994, 2997, 3008, 3010, 3013, 3024, 3025,\n        3035, 3037, 3038, 3040, 3065, 3073, 3087, 3088, 3099, 3102, 3113,\n        3123, 3124, 3148, 3153, 3156, 3157, 3165, 3173, 3175, 3176, 3194,\n        3196, 3202, 3217, 3238, 3239, 3244, 3247, 3260, 3261, 3266, 3267,\n        3271, 3275, 3281, 3288, 3291, 3301, 3328, 3331, 3339, 3340, 3352,\n        3353, 3360, 3361, 3362, 3368, 3382, 3386, 3393, 3412, 3418, 3426,\n        3427, 3429, 3433, 3445, 3455, 3459, 3465, 3471, 3483, 3490, 3499,\n        3505, 3507, 3511, 3515, 3521, 3524, 3526, 3528, 3540, 3542, 3546,\n        3553, 3555, 3556, 3558, 3560, 3603, 3613, 3625, 3639, 3640, 3641,\n        3653, 3655, 3657, 3658, 3659, 3661, 3664, 3665, 3682, 3683, 3694,\n        3714, 3720, 3730, 3739, 3745, 3750, 3751, 3752, 3757, 3761, 3777,\n        3797, 3803, 3805, 3811, 3812, 3826, 3855, 3856, 3857, 3863, 3867,\n        3868, 3875, 3876, 3882, 3883, 3884, 3893, 3905, 3918, 3920, 3922,\n        3924, 3932, 3933, 3939, 3947, 3949, 3955, 3960, 3980, 3985, 3995,\n        4006, 4008, 4010, 4011, 4015, 4025, 4027, 4038, 4044, 4048, 4050,\n        4054, 4055, 4088, 4089, 4091, 4096, 4098, 4109, 4114, 4115, 4117,\n        4125, 4130, 4131, 4133, 4135, 4138, 4141, 4154, 4157, 4164, 4166,\n        4171, 4172, 4190, 4197, 4213, 4217, 4224, 4235, 4240, 4243, 4245,\n        4261, 4263, 4266, 4291, 4294, 4295, 4297, 4298, 4303, 4319, 4321,\n        4325, 4340, 4341, 4348, 4352, 4353, 4366, 4379, 4380, 4382, 4386,\n        4389, 4393, 4407, 4411, 4422, 4425]),\n 16: array([   2,   22,   66,   82,  116,  180,  200,  207,  227,  263,  331,\n         368,  412,  419,  422,  423,  426,  441,  448,  473,  484,  526,\n         530,  531,  545,  559,  580,  589,  597,  615,  624,  658,  678,\n         680,  766,  774,  777,  783,  792,  916,  924,  969,  970,  972,\n        1021, 1051, 1052, 1053, 1093, 1123, 1160, 1205, 1212, 1223, 1267,\n        1272, 1298, 1304, 1310, 1342, 1359, 1408, 1440, 1456, 1470, 1510,\n        1531, 1540, 1549, 1568, 1605, 1616, 1639, 1643, 1649, 1668, 1692,\n        1705, 1713, 1732, 1755, 1765, 1788, 1809, 1822, 1854, 1857, 1875,\n        1877, 1900, 1938, 1953, 1983, 2041, 2077, 2104, 2189, 2199, 2203,\n        2233, 2248, 2254, 2304, 2311, 2313, 2317, 2320, 2331, 2336, 2338,\n        2480, 2508, 2509, 2520, 2524, 2534, 2560, 2591, 2596, 2637, 2685,\n        2699, 2705, 2715, 2719, 2747, 2753, 2754, 2767, 2924, 2963, 2968,\n        2982, 3022, 3086, 3098, 3106, 3142, 3144, 3160, 3203, 3229, 3264,\n        3289, 3333, 3350, 3355, 3401, 3421, 3423, 3442, 3469, 3472, 3495,\n        3501, 3607, 3698, 3728, 3736, 3737, 3754, 3767, 3798, 3822, 3834,\n        3888, 3897, 3902, 3914, 3964, 3965, 4032, 4072, 4080, 4132, 4136,\n        4165, 4202, 4236, 4270, 4273, 4313, 4322, 4329, 4370, 4424]),\n 17: array([   3,   15,   42,   80,  109,  122,  163,  188,  189,  192,  193,\n         261,  298,  306,  375,  379,  396,  397,  399,  449,  492,  494,\n         500,  507,  509,  532,  537,  542,  555,  562,  586,  600,  603,\n         619,  625,  668,  679,  691,  717,  741,  748,  753,  758,  760,\n         763,  786,  787,  789,  813,  815,  839,  865,  892,  903,  904,\n         906,  911,  913,  920,  922,  935,  939,  951,  955,  977, 1002,\n        1012, 1026, 1039, 1043, 1057, 1078, 1085, 1090, 1091, 1106, 1145,\n        1148, 1173, 1187, 1206, 1222, 1238, 1245, 1275, 1276, 1289, 1319,\n        1324, 1351, 1355, 1379, 1406, 1415, 1422, 1433, 1463, 1481, 1496,\n        1498, 1525, 1541, 1559, 1571, 1583, 1596, 1610, 1627, 1656, 1674,\n        1745, 1763, 1775, 1818, 1829, 1838, 1841, 1845, 1866, 1886, 1907,\n        1929, 2018, 2027, 2038, 2049, 2113, 2116, 2120, 2141, 2227, 2269,\n        2285, 2292, 2293, 2330, 2346, 2363, 2392, 2397, 2418, 2425, 2437,\n        2494, 2533, 2538, 2541, 2561, 2581, 2584, 2610, 2613, 2617, 2645,\n        2655, 2666, 2667, 2745, 2794, 2803, 2841, 2844, 2905, 2922, 2941,\n        2950, 2957, 2966, 2970, 3005, 3006, 3093, 3115, 3137, 3155, 3159,\n        3177, 3188, 3197, 3205, 3209, 3215, 3223, 3270, 3273, 3335, 3373,\n        3379, 3383, 3384, 3388, 3392, 3396, 3407, 3416, 3463, 3477, 3494,\n        3497, 3502, 3529, 3559, 3618, 3620, 3643, 3695, 3705, 3726, 3740,\n        3775, 3789, 3817, 3821, 3842, 3845, 3861, 3903, 3906, 3916, 3928,\n        3934, 3963, 3977, 4000, 4014, 4039, 4066, 4094, 4123, 4146, 4160,\n        4200, 4212, 4230, 4254, 4262, 4274, 4293, 4311, 4324, 4360, 4363,\n        4378, 4392, 4415]),\n 18: array([   4,    8,   11, ..., 4421, 4427, 4428])}"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaf_samples_indices"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T16:54:33.802069Z",
     "start_time": "2024-08-28T16:54:33.796010Z"
    }
   },
   "id": "842b69204fdb5835"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load test accuracies per leaf for the blackbox x->y model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b81c798567e474f"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "output_path = \"/Users/gouse/PycharmProjects/AR-Imperial-Thesis/logs_and_models_to_show/analysis_notebooks/completeness_scores/blackbox_model/test_pred_correct_or_not_xtoy.pkl\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T16:54:33.802577Z",
     "start_time": "2024-08-28T16:54:33.799301Z"
    }
   },
   "id": "4092fb8253673f1e"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test dataset:  4430\n",
      "Accuracy of the blackbox model:  99.50338745117188\n"
     ]
    }
   ],
   "source": [
    "# open pickle file\n",
    "with open(output_path, 'rb') as f:\n",
    "    test_pred_correct_or_not_xtoy = pkl.load(f)\n",
    "\n",
    "print(\"Length of test dataset: \", len(test_pred_correct_or_not_xtoy))\n",
    "acc = test_pred_correct_or_not_xtoy.sum() * 100/len(test_pred_correct_or_not_xtoy)\n",
    "print(\"Accuracy of the blackbox model: \", acc.item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T16:54:33.808482Z",
     "start_time": "2024-08-28T16:54:33.803273Z"
    }
   },
   "id": "bfc56b849bd37344"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "{4: 0.9987179636955261,\n 6: 0.9931972622871399,\n 7: 0.9959349632263184,\n 10: 1.0,\n 11: 0.9933333396911621,\n 12: 0.9933333396911621,\n 15: 0.9969969987869263,\n 16: 0.9946236610412598,\n 17: 0.9959183931350708,\n 18: 0.9912629127502441}"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the acuracy of the blackbox model per leaf\n",
    "accuracy_per_path_blackbox_dict = {}\n",
    "for path in leaf_samples_indices.keys():\n",
    "    indices = leaf_samples_indices[path]\n",
    "    accuracy_per_path_blackbox_dict[path] = (test_pred_correct_or_not_xtoy[indices].sum()/len(indices)).item()\n",
    "    \n",
    "accuracy_per_path_blackbox_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T16:54:33.839050Z",
     "start_time": "2024-08-28T16:54:33.810493Z"
    }
   },
   "id": "9ff1ab02ef8e9595"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Compute the test completeness scores"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b44ad6733726ea50"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "acuracy_of_random_guessing = 1/3\n",
    "\n",
    "completeness_scores_per_original_path = {}\n",
    "for path in accuracy_per_original_path_dict.keys():\n",
    "    completeness_scores_per_original_path[path] = (accuracy_per_original_path_dict[path] - acuracy_of_random_guessing) / (accuracy_per_path_blackbox_dict[path]  - acuracy_of_random_guessing)\n",
    "    \n",
    "completeness_scores_per_new_path = {}\n",
    "for path in accuracy_per_new_path_dict.keys():\n",
    "    completeness_scores_per_new_path[path] = (accuracy_per_new_path_dict[path] - acuracy_of_random_guessing) / (accuracy_per_path_blackbox_dict[path]  - acuracy_of_random_guessing)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T16:54:33.839408Z",
     "start_time": "2024-08-28T16:54:33.815523Z"
    }
   },
   "id": "89d5a4f444c6556d"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original path: 4, Completeness score: 0.4123313972696226\n",
      "Original path: 6, Completeness score: 0.02061855722048902\n",
      "Original path: 7, Completeness score: 0.3619631880662883\n",
      "Original path: 10, Completeness score: 0.23170731707317072\n",
      "Original path: 11, Completeness score: 0.19191919007042021\n",
      "Original path: 12, Completeness score: 0.46464646017049094\n",
      "Original path: 15, Completeness score: 0.24660633417652114\n",
      "Original path: 16, Completeness score: 0.24390243713330498\n",
      "Original path: 17, Completeness score: 0.944558484797899\n",
      "Original path: 18, Completeness score: 0.6173038176072825\n",
      "New path: 4, Completeness score: 0.4123313972696226\n",
      "New path: 6, Completeness score: 0.21649485081513445\n",
      "New path: 7, Completeness score: 0.3619631880662883\n",
      "New path: 10, Completeness score: 0.23170731707317072\n",
      "New path: 11, Completeness score: 0.19191919007042021\n",
      "New path: 12, Completeness score: 0.46464646017049094\n",
      "New path: 15, Completeness score: 0.24660633417652114\n",
      "New path: 16, Completeness score: 0.24390243713330498\n",
      "New path: 17, Completeness score: 0.944558484797899\n",
      "New path: 18, Completeness score: 0.7006036156807554\n"
     ]
    }
   ],
   "source": [
    "for path in completeness_scores_per_original_path.keys():\n",
    "    print(f\"Original path: {path}, Completeness score: {completeness_scores_per_original_path[path]}\")\n",
    "    \n",
    "for path in completeness_scores_per_new_path.keys():\n",
    "    print(f\"New path: {path}, Completeness score: {completeness_scores_per_new_path[path]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T16:54:33.839596Z",
     "start_time": "2024-08-28T16:54:33.817750Z"
    }
   },
   "id": "5bc9efe4e54fb3ed"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T16:54:33.839669Z",
     "start_time": "2024-08-28T16:54:33.820685Z"
    }
   },
   "id": "d1b859925407af73"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
